{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2368cd69-5209-43e5-b5f5-d2946a9ed25b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- TV: double (nullable = true)\n |-- Radio: double (nullable = true)\n |-- Newspaper: double (nullable = true)\n |-- Sales: double (nullable = true)\n\n+-----+-----+---------+-----+\n|   TV|Radio|Newspaper|Sales|\n+-----+-----+---------+-----+\n|230.1| 37.8|     69.2| 22.1|\n| 44.5| 39.3|     45.1| 10.4|\n| 17.2| 45.9|     69.3|  9.3|\n|151.5| 41.3|     58.5| 18.5|\n|180.8| 10.8|     58.4| 12.9|\n+-----+-----+---------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#y = b0 + b1*x\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Linear Regression with PySpark') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.format('delta').\\\n",
    "    options(header = 'true', inferschema = 'true').\\\n",
    "    load(\"/user/hive/warehouse/advertising\", header = True)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df871da-5142-42e4-8234-49ddae8ebb4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n|summary|               TV|             Radio|         Newspaper|             Sales|\n+-------+-----------------+------------------+------------------+------------------+\n|  count|              200|               200|               200|               200|\n|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n|    min|              0.7|               0.0|               0.3|               1.6|\n|    max|            296.4|              49.6|             114.0|              27.0|\n+-------+-----------------+------------------+------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3510b437-2a07-4830-8133-c8069353684f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n|         features|label|\n+-----------------+-----+\n|[230.1,37.8,69.2]| 22.1|\n| [44.5,39.3,45.1]| 10.4|\n| [17.2,45.9,69.3]|  9.3|\n|[151.5,41.3,58.5]| 18.5|\n|[180.8,10.8,58.4]| 12.9|\n+-----------------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r : [Vectors.dense(r[:-1]), r[-1]]).toDF(['features', 'label'])\n",
    "\n",
    "transformed = transData(df)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d404853-88c2-415d-bce7-9fd33e0b2360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+-----------------+\n|         features|label|  indexedFeatures|\n+-----------------+-----+-----------------+\n|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|\n| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|\n| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|\n|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|\n|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|\n+-----------------+-----+-----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol = \"features\", outputCol = \"indexedFeatures\", maxCategories = 4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)\n",
    "\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2bc613d-7b82-40fe-87d9-194d2718f380",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+---------------+\n|       features|label|indexedFeatures|\n+---------------+-----+---------------+\n| [0.7,39.6,8.7]|  1.6| [0.7,39.6,8.7]|\n| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|\n| [5.4,29.9,9.4]|  5.3| [5.4,29.9,9.4]|\n|[7.3,28.1,41.4]|  5.5|[7.3,28.1,41.4]|\n|[7.8,38.9,50.6]|  6.6|[7.8,38.9,50.6]|\n+---------------+-----+---------------+\nonly showing top 5 rows\n\n+----------------+-----+----------------+\n|        features|label| indexedFeatures|\n+----------------+-----+----------------+\n|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n|   [8.6,2.1,1.0]|  4.8|   [8.6,2.1,1.0]|\n| [8.7,48.9,75.0]|  7.2| [8.7,48.9,75.0]|\n|[13.2,15.9,49.6]|  5.6|[13.2,15.9,49.6]|\n|[18.7,12.1,23.4]|  6.7|[18.7,12.1,23.4]|\n+----------------+-----+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "trainingData.show(5)\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bedc939e-99b7-4f47-9a40-b6964d9c8947",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "pipeline = Pipeline(stages = [featureIndexer, lr])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f5102d-c0f5-4d72-9e27-8983a4c76876",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+------------------+\n|        features|label|        prediction|\n+----------------+-----+------------------+\n|  [8.4,27.2,2.1]|  5.7| 8.229211181760627|\n|   [8.6,2.1,1.0]|  4.8| 3.644851163299394|\n| [8.7,48.9,75.0]|  7.2|12.020689858644344|\n|[13.2,15.9,49.6]|  5.6|  6.25831749737122|\n|[18.7,12.1,23.4]|  6.7| 5.893004667299868|\n+----------------+-----+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c828be1-7ec4-4fc8-adf3-67e20b583020",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Square Error (RMSE) on test data = 1.55713\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol = 'label', predictionCol = 'prediction', metricName = 'rmse')\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root Mean Square Error (RMSE) on test data = %g' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c87da307-16aa-41b2-b429-7cc53d7ee3e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.8899337308584387\n"
     ]
    }
   ],
   "source": [
    "#r2-score hesabÄ±\n",
    "\n",
    "y_true = predictions.select('label').toPandas()\n",
    "y_pred = predictions.select('prediction').toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84eea05d-8018-4f69-93b5-ba9eaea5b6dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06824127-5c6a-48c3-9b9d-f728a07682c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('DT Classification with Pyspark') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2a61147-fe4b-462b-9b04-1d979140ef88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n|          7.8|            0.88|        0.0|           2.6|    0.098|               25.0|                67.0| 0.9968| 3.2|     0.68|    9.8|      5|\n|          7.8|            0.76|       0.04|           2.3|    0.092|               15.0|                54.0|  0.997|3.26|     0.65|    9.8|      5|\n|         11.2|            0.28|       0.56|           1.9|    0.075|               17.0|                60.0|  0.998|3.16|     0.58|    9.8|      6|\n|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|      5|\n+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('delta').\\\n",
    "    options(header = 'true', inferschema = 'true')\\\n",
    "    .load(\"/user/hive/warehouse/wine_data\", header = 'True')\n",
    "\n",
    "df.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acea6e1c-fae9-41c0-b071-58a429e8e7d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def condition(r):\n",
    "\n",
    "    if (0 <= r <= 4):\n",
    "        label = 'low'\n",
    "    \n",
    "    elif (4 < r <= 6):\n",
    "        label = 'medium'\n",
    "\n",
    "    else:\n",
    "        label = 'high'\n",
    "    \n",
    "    return label\n",
    "\n",
    "def string_to_float(x):\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77ea88fe-f733-4139-9eb5-12780aafc42b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4| medium|\n|          7.8|            0.88|        0.0|           2.6|    0.098|               25.0|                67.0| 0.9968| 3.2|     0.68|    9.8| medium|\n|          7.8|            0.76|       0.04|           2.3|    0.092|               15.0|                54.0|  0.997|3.26|     0.65|    9.8| medium|\n|         11.2|            0.28|       0.56|           1.9|    0.075|               17.0|                60.0|  0.998|3.16|     0.58|    9.8| medium|\n|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4| medium|\n+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\nonly showing top 5 rows\n\nroot\n |-- fixed acidity: double (nullable = true)\n |-- volatile acidity: double (nullable = true)\n |-- citric acid: double (nullable = true)\n |-- residual sugar: double (nullable = true)\n |-- chlorides: double (nullable = true)\n |-- free sulfur dioxide: double (nullable = true)\n |-- total sulfur dioxide: double (nullable = true)\n |-- density: double (nullable = true)\n |-- pH: double (nullable = true)\n |-- sulphates: double (nullable = true)\n |-- alcohol: double (nullable = true)\n |-- quality: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "string_to_float_udf = udf(string_to_float, DoubleType())\n",
    "quality_udf = udf(lambda x : condition(x), StringType())\n",
    "\n",
    "df = df.withColumn(\"quality\", quality_udf(\"quality\"))\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0148bf86-6375-4a52-bc48-2d12298a7ca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorIndexer, StringIndexer, IndexToString\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9746597-215f-4a67-bdde-9ae9f7572597",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n|            features| label|\n+--------------------+------+\n|[7.4,0.7,0.0,1.9,...|medium|\n|[7.8,0.88,0.0,2.6...|medium|\n|[7.8,0.76,0.04,2....|medium|\n|[11.2,0.28,0.56,1...|medium|\n|[7.4,0.7,0.0,1.9,...|medium|\n+--------------------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "def transData(data):\n",
    "    return data.rdd.map(lambda r : [Vectors.dense(r[:-1]), r[-1]]).toDF(['features', 'label'])\n",
    "\n",
    "transformed = transData(df)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b1add08-df27-4be3-a9ab-b08ff21c1f9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06072023 - DEB",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
