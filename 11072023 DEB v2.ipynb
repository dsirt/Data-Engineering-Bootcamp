{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b070d9-8cee-4d5b-ae3d-ad44614f153c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"RFM Customer Segmentation with PySpark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09fbf487-e2cd-439e-a07a-19ccfdb2c159",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw = spark.read.format('delta').\\\n",
    "    options(header = 'true', inferschema = 'true').\\\n",
    "    load(\"/user/hive/warehouse/online_retail2\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dde06e7-64c1-431c-88a7-39401b30a751",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2,55|     17850|United Kingdom|\n|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2,75|     17850|United Kingdom|\n|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|\n+---------+---------+--------------------+--------+---------------+---------+----------+--------------+\nonly showing top 5 rows\n\nroot\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: long (nullable = true)\n |-- InvoiceDate: string (nullable = true)\n |-- UnitPrice: string (nullable = true)\n |-- CustomerID: long (nullable = true)\n |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_raw.show(5)\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d987ba2c-dda9-4bb5-96e5-8081409408ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n+---------+---------+-----------+--------+-----------+---------+----------+-------+\n|   541909|   541909|     541909|  541909|     541909|   541909|    541909| 541909|\n+---------+---------+-----------+--------+-----------+---------+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "def my_count(df_in):\n",
    "    df_in.agg(*[count(c).alias(c) for c in df_in.columns]).show()\n",
    "\n",
    "my_count(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f21365b1-3e8a-44be-a21e-75a90fb16efa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n+---------+---------+-----------+--------+-----------+---------+----------+-------+\n|   541909|   541909|     541909|  541909|     541909|   541909|    541909| 541909|\n+---------+---------+-----------+--------+-----------+---------+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df_raw.dropna(how = \"any\")\n",
    "my_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ca2c15-48f7-4541-b1df-0e0443b5eb3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+---------------+---------+----------+--------------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|    InvoiceDate|UnitPrice|CustomerID|       Country|NewInvoiceDate|\n+---------+---------+--------------------+--------+---------------+---------+----------+--------------+--------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|1.12.2010 08:26|     2,55|     17850|United Kingdom|          null|\n|   536365|    71053| WHITE METAL LANTERN|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|          null|\n|   536365|   84406B|CREAM CUPID HEART...|       8|1.12.2010 08:26|     2,75|     17850|United Kingdom|          null|\n|   536365|   84029G|KNITTED UNION FLA...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|          null|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|1.12.2010 08:26|     3,39|     17850|United Kingdom|          null|\n+---------+---------+--------------------+--------+---------------+---------+----------+--------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_utc_timestamp, unix_timestamp, lit, datediff, col, when\n",
    "\n",
    "timeFmt = \"MM/dd/yy HH:mm\"\n",
    "\n",
    "df = df.withColumn('NewInvoiceDate', when(col('InvoiceDate').isNotNull(), to_utc_timestamp(unix_timestamp(col('InvoiceDate'), timeFmt).cast('timestamp'), 'UTC')).otherwise(col('InvoiceDate')))\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5f96fc-394f-44bd-87bd-4364c67d92c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+\n|CustomerID|Recency|Frequency|Monetary|\n+----------+-------+---------+--------+\n|     15194|   null|       22|    null|\n|     17703|   null|        3|    null|\n|     13452|   null|        2|   590.0|\n|     13098|   null|       41|    null|\n|     17048|   null|        6|    null|\n|     13638|   null|        1|    null|\n|     15322|   null|        2|    null|\n|     13723|   null|        1|    null|\n|     16597|   null|        1|    null|\n|     15237|   null|        4|    null|\n|     13248|   null|        2|    null|\n|     16742|   null|        2|    null|\n|     14719|   null|        6|    null|\n|     17043|   null|        4|    null|\n|     14117|   null|        1|    null|\n|     15057|   null|        2|    null|\n|     17979|   null|        5|    null|\n|     13460|   null|        2|    null|\n|     13518|   null|        1|    null|\n|     15432|   null|        1|    null|\n+----------+-------+---------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "df = df.withColumn('TotalPrice', round(df.Quantity * df.UnitPrice, 2) )\n",
    "\n",
    "from pyspark.sql.functions import mean, min, max, sum, datediff, to_date\n",
    "\n",
    "date_max = df.select(max('NewInvoiceDate')).toPandas()\n",
    "\n",
    "current = to_utc_timestamp(unix_timestamp(lit(str(date_max.iloc[0][0])), 'yy-MM-dd HH:mm').cast('timestamp'), 'UTC')\n",
    "\n",
    "df = df.withColumn('Duration', datediff(lit(current), 'NewInvoiceDate'))\n",
    "\n",
    "#Recency, Frequency, Monetary\n",
    "\n",
    "recency = df.groupBy('CustomerID').agg(min('Duration').alias('Recency'))\n",
    "\n",
    "frequency = df.groupBy('CustomerID', 'InvoiceNo').count()\\\n",
    "    .groupBy('CustomerID')\\\n",
    "    .agg(count('*').alias(\"Frequency\"))\n",
    "\n",
    "monetary = df.groupBy('CustomerID').agg(round(sum('TotalPrice'), 2).alias('Monetary'))\n",
    "\n",
    "rfm = recency.join(frequency, 'CustomerID', how = 'inner')\\\n",
    "    .join(monetary, 'CustomerID', how = 'inner')\n",
    "\n",
    "rfm.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11072023 DEB v2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
